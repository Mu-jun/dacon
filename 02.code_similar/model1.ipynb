{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import itertools as it\n",
    "import functools as fn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('./dataset/data_df.csv')\n",
    "data_df = pd.read_csv(data_path)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(code):\n",
    "    code = re.sub(r'    ',r'\\t ',code)\n",
    "    code = re.sub(r\"#.*\\n\",'\\n',code) # 주석제거\n",
    "    code = re.sub(r\"import.*\\n\",'',code) # 모듈 참고 안함\n",
    "    code = re.sub(r'\"',r\"'\",code)\n",
    "    code = re.sub(r\"([\\n:(){}\\[\\]\\*\\/\\%\\+\\-\\,\\=.'])\",r' \\1 ',code)\n",
    "    code = re.sub(r'\\n',r\"<n>\",code)\n",
    "    code = re.sub(r'\\t',r\"<t>\",code)\n",
    "    return code.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import config as cfg\n",
    "\n",
    "with open(data_df.code1[0],'r') as f:\n",
    "    code1 = f.read()\n",
    "with open(data_df.code2[0],'r') as f:\n",
    "    code2 = f.read()\n",
    "    \n",
    "code_docs = [code1,code2]\n",
    "\n",
    "for i in range(len(code_docs)):\n",
    "    code_docs[i] = preprocessing(code_docs[i])\n",
    "\n",
    "print(f'{len(code_docs)=}')    \n",
    "# print(code_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어장 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "code_path = './dataset/code/'\n",
    "classes = os.listdir(code_path)\n",
    "source_list = []\n",
    "for label in classes:\n",
    "    filenames = os.listdir(code_path+label)\n",
    "    for file in filenames:\n",
    "        source_list.append(code_path+label+'/'+file)\n",
    "\n",
    "# source_list[145:155]\n",
    "len(source_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(source_list[478])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_docs = []\n",
    "for src_path in tqdm(source_list):\n",
    "    with open(src_path,'r',encoding='utf-8') as f:\n",
    "        code_docs.append(f.read())\n",
    "len(code_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(code_doc) for code_doc in code_docs])\n",
    "print(f'{max_len=}')\n",
    "max_len_id = np.argmax([len(code_doc) for code_doc in code_docs])\n",
    "print(source_list[max_len_id])\n",
    "# print(code_docs[max_len_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_code = max(code_docs)\n",
    "print(\"code_docs.index(max_id)\")\n",
    "print(code_docs.index(max_code))\n",
    "print()\n",
    "print(\"source_list[code_docs.index(max_id)]\")\n",
    "print(source_list[code_docs.index(max_code)])\n",
    "print()\n",
    "# print(max_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import config as cfg\n",
    "\n",
    "for i in tqdm(range(len(code_docs))):\n",
    "    code_docs[i] = preprocessing(code_docs[i]).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(code_doc) for code_doc in code_docs])\n",
    "print(f'{max_len=}')\n",
    "max_len_id = np.argmax([len(code_doc) for code_doc in code_docs])\n",
    "print(source_list[max_len_id])\n",
    "# print(code_docs[max_len_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_code = max(code_docs)\n",
    "print(\"code_docs.index(max_id)\")\n",
    "print(code_docs.index(max_code))\n",
    "print()\n",
    "print(\"source_list[code_docs.index(max_id)]\")\n",
    "print(source_list[code_docs.index(max_code)])\n",
    "print()\n",
    "# print(max_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "for code_doc in tqdm(code_docs):\n",
    "    # code_doc = np.concatenate(code_doc).tolist() # 메모리 부족....\n",
    "    counter += Counter(code_doc)\n",
    "most_counter = counter.most_common(10000-2)\n",
    "vocab = ['<pad>','<unk>']+[key for key, _ in most_counter]\n",
    "# print(vocab)\n",
    "word_to_index = {word:index for index, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(word_to_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input pipe line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del code_docs\n",
    "del most_counter\n",
    "del source_list\n",
    "del counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(path):\n",
    "    with open(path,'r',encoding='utf8') as f:\n",
    "        code = f.read()\n",
    "    words = preprocessing(code)\n",
    "    code_sequence = [word_to_index[word] if word in word_to_index else word_to_index['<unk>'] for word in words]\n",
    "    return code_sequence\n",
    "\n",
    "def make_tensor(paths):\n",
    "    code_sequences = []\n",
    "    for path in tqdm(paths):\n",
    "        code_sequences.append(tokenize(path))\n",
    "    pad_sequences = keras.preprocessing.sequence.pad_sequences(code_sequences,maxlen=cfg.max_len,truncating='pre')\n",
    "    return pad_sequences\n",
    "    \n",
    "def make_dataset(code1_paths,code2_paths,similar):\n",
    "    code1_tensor = make_tensor(code1_paths)\n",
    "    code1_ds = tf.data.Dataset.from_tensor_slices(code1_tensor)\n",
    "    code2_tensor = make_tensor(code2_paths)\n",
    "    code2_ds = tf.data.Dataset.from_tensor_slices(code2_tensor)\n",
    "    code_ds = tf.data.Dataset.zip((code1_ds,code2_ds))\n",
    "    similar_ds = tf.data.Dataset.from_tensor_slices(similar)\n",
    "    ds = tf.data.Dataset.zip((code_ds,similar_ds))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ds = make_dataset(data_df['code1'],data_df['code2'],data_df['similar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code1, code2, similar in data_ds.take(1):\n",
    "    print(code1.shape)\n",
    "    print(code2.shape)\n",
    "    print(similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_ds = int(len(data_ds)*0.8)\n",
    "print(f\"{num_train_ds=}\")\n",
    "num_val_ds = len(data_ds)-num_train_ds\n",
    "print(f\"{num_val_ds=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = data_ds.take(num_train_ds)\n",
    "val_ds = data_ds.skip(num_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(train_ds)=}\")\n",
    "print(f\"{len(val_ds)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀프 어텐션\n",
    "d_model = 512\n",
    "num_layers = 6\n",
    "num_heads = 8\n",
    "dff = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 포지셔널 인코딩(Positional Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 마스킹(making)\n",
    "- 패딩을 계산하지 않게 해줌."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스케일드 닷-프로덕트 어텐션(Scaled dot-product Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead)\n",
    "  but it must be broadcastable for addition.\n",
    "\n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable\n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                    (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2\n",
    "    \n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "        # self.pos_encoding = tf.keras.layers.Embedding(input_vocab_size, d_model) => 포지션 임베딩 : Bert에서 사용하는 방법\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                       for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "def code_similar_model (num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, training=False, rate=0.1):\n",
    "    encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate)\n",
    "    \n",
    "    code1 = tf.keras.Input(shape=(None,), name=\"code1\")\n",
    "    code2 = tf.keras.Input(shape=(None,), name=\"code2\")\n",
    "    \n",
    "    code1_enc_padding_mask = create_padding_mask(code1)\n",
    "    code1 = encoder(code1, training, code1_enc_padding_mask)\n",
    "    # code1.shape = (batch_size, inp_seq_len, d_model)\n",
    "    code2_enc_padding_mask = create_padding_mask(code2)\n",
    "    code2 = encoder(code2, training, code2_enc_padding_mask)\n",
    "    # code2.shape = (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    code2 = tf.transpose(code2,[0,2,1])\n",
    "    x = tf.matmul(code1,code2)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = tf.keras.layers.Dropout(rate)(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    return  tf.keras.Model(inputs=[code1,code2],\n",
    "                           outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d2432c1d6e84635d51706be02c2d8538e2b3a500c4f9828f5f40c57643f2213"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('MA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
