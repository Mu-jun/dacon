{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4642be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af512893",
   "metadata": {},
   "source": [
    "# tf input pipline\n",
    "## tf.data.dataset 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2019b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./dataset/main_directory/\"\n",
    "test_path = \"./dataset/test/\"\n",
    "\n",
    "INPUT_SHAPE = (224,224,3)\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "tf.random.set_seed(7)\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0779fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(filename):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img,INPUT_SHAPE[:2])\n",
    "    return img\n",
    "\n",
    "def make_dataset(filepaths,labels):\n",
    "    filenames_ds = tf.data.Dataset.from_tensor_slices(filepaths)\n",
    "    images_ds = filenames_ds.map(\n",
    "        parse_image,\n",
    "        num_parallel_calls=AUTOTUNE\n",
    "    )\n",
    "    labels_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    ds = tf.data.Dataset.zip((images_ds, labels_ds))\n",
    "    return ds\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29e61416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes : 11\n",
      "number of images : 858\n",
      "./dataset/main_directory\\1\\1_train_031.png\n",
      "1\n",
      "\n",
      "data 5 preview\n",
      "./dataset/main_directory\\5\\5_train_617.png\n",
      "class : 5\n",
      "./dataset/main_directory\\8\\8_train_838.png\n",
      "class : 8\n",
      "./dataset/main_directory\\9\\9_train_387.png\n",
      "class : 9\n",
      "./dataset/main_directory\\8\\8_train_007.png\n",
      "class : 8\n",
      "./dataset/main_directory\\4\\4_train_504.png\n",
      "class : 4\n"
     ]
    }
   ],
   "source": [
    "classes = os.listdir(train_path)\n",
    "num_classes = len(classes)\n",
    "print(\"number of classes :\", num_classes)\n",
    "\n",
    "filenames = glob(train_path+'*/*')\n",
    "num_images = len(filenames)\n",
    "print(\"number of images :\", num_images)\n",
    "\n",
    "print(filenames[0])\n",
    "print(filenames[0].split(os.sep)[-2])\n",
    "print()\n",
    "\n",
    "np.random.shuffle(filenames)\n",
    "labels = [classes.index(fn.split(os.sep)[-2]) for fn in filenames]\n",
    "\n",
    "print(\"data 5 preview\")\n",
    "for path,label in zip(filenames[:5],labels[:5]):\n",
    "    print(path)\n",
    "    print(\"class :\",classes[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52580d6a",
   "metadata": {},
   "source": [
    "# 학습셋, 검증셋으로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89aaea30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training data : 686\n",
      "number of validation data : 172\n",
      "data 5 preview\n",
      "./dataset/main_directory\\8\\8_train_703.png\n",
      "class : 8\n",
      "./dataset/main_directory\\5\\5_train_442.png\n",
      "class : 5\n",
      "./dataset/main_directory\\5\\5_train_611.png\n",
      "class : 5\n",
      "./dataset/main_directory\\4\\4_train_796.png\n",
      "class : 4\n",
      "./dataset/main_directory\\10-1\\10-1_train_390.png\n",
      "class : 10-1\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(\n",
    "    filenames, labels, test_size=0.2,\n",
    "    stratify=labels, random_state=1\n",
    ")\n",
    "num_train = len(train_x)\n",
    "num_val = len(val_x)\n",
    "print(\"number of training data :\", num_train)\n",
    "print(\"number of validation data :\", num_val)\n",
    "\n",
    "print(\"data 5 preview\")\n",
    "for path,label in zip(train_x[:5],train_y[:5]):\n",
    "    print(path)\n",
    "    print(\"class :\",classes[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad436c5",
   "metadata": {},
   "source": [
    "# tf dataset 객체 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28a1f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = make_dataset(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ecf94b",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# tf.data.dataset 확인\n",
    "\n",
    "for img, label in train_ds.take(5):\n",
    "    # print(img.numpy().shape)\n",
    "    img = img.numpy()\n",
    "    # print(img.min(), img.max())\n",
    "    \n",
    "    img = img.astype(np.uint8)\n",
    "    idx = (label.numpy())\n",
    "    \n",
    "    plt.imshow(img), plt.axis('off')\n",
    "    plt.title(classes[idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e764d72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = make_dataset(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a3e5691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 성능 높이기\n",
    "train_ds = configure_for_performance(train_ds)\n",
    "val_ds = configure_for_performance(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1974c928",
   "metadata": {},
   "source": [
    "tf.data.experimental.save(train_ds, \"train_ds\", compression=\"GZIP\")\n",
    "tf.data.experimental.save(val_ds, \"val_ds\", compression=\"GZIP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d4c0b",
   "metadata": {},
   "source": [
    "train_ds = tf.data.experimental.load(\"train_ds\", compression=\"GZIP\")\n",
    "val_ds = tf.data.experimental.load(\"val_ds\", compression=\"GZIP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b12369",
   "metadata": {},
   "source": [
    "# data augmentation layer\n",
    "## evaluate() 또는 predict() 호출 시에는 자동으로 비활성화 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ee8c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "    keras.layers.experimental.preprocessing.RandomTranslation(0.1,0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc848d0",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "103a8d62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transfer_model = keras.applications.Xception(\n",
    "    input_shape= INPUT_SHAPE,\n",
    "    include_top= False,\n",
    "    weights= 'imagenet',\n",
    ")\n",
    "transfer_model.trainable = False\n",
    "# transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ac2f51f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "finetune_model = keras.Sequential([\n",
    "    keras.Input(shape=INPUT_SHAPE),\n",
    "    data_augmentation,\n",
    "    keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    transfer_model,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(2000, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1000, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(500, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "# finetune_model.summary()\n",
    "\n",
    "finetune_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer=keras.optimizers.Adam(learning_rate=0.0002),\n",
    "                       metrics='accuracy')                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d5fbc2",
   "metadata": {},
   "source": [
    "# batch 데이터셋 확인\n",
    "\n",
    "for batch in train_ds.take(1):\n",
    "    for i in range(5):\n",
    "        img = batch[0][i]\n",
    "        # print(img.numpy().shape)\n",
    "        img = img.numpy()\n",
    "        # print(img.min(), img.max())\n",
    "        \n",
    "        img = img.astype(np.uint8)\n",
    "        \n",
    "        label = batch[1][i]\n",
    "        idx = (label.numpy())\n",
    "        \n",
    "        plt.imshow(img), plt.axis('off')\n",
    "        plt.title(classes[idx])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3499551b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 3.3380 - accuracy: 0.1280\n",
      "Epoch 1: val_loss improved from inf to 2.11878, saving model to ./model\\001-2.1188.h5\n",
      "21/21 [==============================] - 133s 6s/step - loss: 3.3380 - accuracy: 0.1280 - val_loss: 2.1188 - val_accuracy: 0.2313\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.5001 - accuracy: 0.2125\n",
      "Epoch 2: val_loss improved from 2.11878 to 2.00672, saving model to ./model\\002-2.0067.h5\n",
      "21/21 [==============================] - 117s 6s/step - loss: 2.5001 - accuracy: 0.2125 - val_loss: 2.0067 - val_accuracy: 0.3250\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.2829 - accuracy: 0.2370\n",
      "Epoch 3: val_loss improved from 2.00672 to 1.76597, saving model to ./model\\003-1.7660.h5\n",
      "21/21 [==============================] - 119s 6s/step - loss: 2.2829 - accuracy: 0.2370 - val_loss: 1.7660 - val_accuracy: 0.4062\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.0222 - accuracy: 0.3119\n",
      "Epoch 4: val_loss improved from 1.76597 to 1.62146, saving model to ./model\\004-1.6215.h5\n",
      "21/21 [==============================] - 115s 6s/step - loss: 2.0222 - accuracy: 0.3119 - val_loss: 1.6215 - val_accuracy: 0.4563\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.8384 - accuracy: 0.3394\n",
      "Epoch 5: val_loss improved from 1.62146 to 1.44224, saving model to ./model\\005-1.4422.h5\n",
      "21/21 [==============================] - 113s 5s/step - loss: 1.8384 - accuracy: 0.3394 - val_loss: 1.4422 - val_accuracy: 0.4938\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.7119 - accuracy: 0.4052\n",
      "Epoch 6: val_loss improved from 1.44224 to 1.38465, saving model to ./model\\006-1.3846.h5\n",
      "21/21 [==============================] - 113s 5s/step - loss: 1.7119 - accuracy: 0.4052 - val_loss: 1.3846 - val_accuracy: 0.5125\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.5241 - accuracy: 0.4526\n",
      "Epoch 7: val_loss improved from 1.38465 to 1.22626, saving model to ./model\\007-1.2263.h5\n",
      "21/21 [==============================] - 114s 5s/step - loss: 1.5241 - accuracy: 0.4526 - val_loss: 1.2263 - val_accuracy: 0.5312\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.4325 - accuracy: 0.4893\n",
      "Epoch 8: val_loss improved from 1.22626 to 1.11325, saving model to ./model\\008-1.1133.h5\n",
      "21/21 [==============================] - 113s 5s/step - loss: 1.4325 - accuracy: 0.4893 - val_loss: 1.1133 - val_accuracy: 0.5813\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.3957 - accuracy: 0.5138\n",
      "Epoch 9: val_loss improved from 1.11325 to 1.04640, saving model to ./model\\009-1.0464.h5\n",
      "21/21 [==============================] - 120s 6s/step - loss: 1.3957 - accuracy: 0.5138 - val_loss: 1.0464 - val_accuracy: 0.5938\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.2850 - accuracy: 0.5489\n",
      "Epoch 10: val_loss improved from 1.04640 to 0.92566, saving model to ./model\\010-0.9257.h5\n",
      "21/21 [==============================] - 118s 6s/step - loss: 1.2850 - accuracy: 0.5489 - val_loss: 0.9257 - val_accuracy: 0.6500\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.0579 - accuracy: 0.6300\n",
      "Epoch 11: val_loss improved from 0.92566 to 0.91197, saving model to ./model\\011-0.9120.h5\n",
      "21/21 [==============================] - 112s 5s/step - loss: 1.0579 - accuracy: 0.6300 - val_loss: 0.9120 - val_accuracy: 0.6750\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 1.0259 - accuracy: 0.6315\n",
      "Epoch 12: val_loss improved from 0.91197 to 0.79346, saving model to ./model\\012-0.7935.h5\n",
      "21/21 [==============================] - 115s 6s/step - loss: 1.0259 - accuracy: 0.6315 - val_loss: 0.7935 - val_accuracy: 0.7125\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.9910 - accuracy: 0.6407\n",
      "Epoch 13: val_loss did not improve from 0.79346\n",
      "21/21 [==============================] - 110s 5s/step - loss: 0.9910 - accuracy: 0.6407 - val_loss: 0.8785 - val_accuracy: 0.6375\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.9433 - accuracy: 0.6560\n",
      "Epoch 14: val_loss improved from 0.79346 to 0.75784, saving model to ./model\\014-0.7578.h5\n",
      "21/21 [==============================] - 111s 5s/step - loss: 0.9433 - accuracy: 0.6560 - val_loss: 0.7578 - val_accuracy: 0.7250\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.9023 - accuracy: 0.6606\n",
      "Epoch 15: val_loss improved from 0.75784 to 0.69397, saving model to ./model\\015-0.6940.h5\n",
      "21/21 [==============================] - 112s 5s/step - loss: 0.9023 - accuracy: 0.6606 - val_loss: 0.6940 - val_accuracy: 0.7437\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.8187 - accuracy: 0.6758\n",
      "Epoch 16: val_loss did not improve from 0.69397\n",
      "21/21 [==============================] - 106s 5s/step - loss: 0.8187 - accuracy: 0.6758 - val_loss: 0.7629 - val_accuracy: 0.6875\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.7654 - accuracy: 0.7080\n",
      "Epoch 17: val_loss improved from 0.69397 to 0.69113, saving model to ./model\\017-0.6911.h5\n",
      "21/21 [==============================] - 111s 5s/step - loss: 0.7654 - accuracy: 0.7080 - val_loss: 0.6911 - val_accuracy: 0.7563\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.6860 - accuracy: 0.7385\n",
      "Epoch 18: val_loss improved from 0.69113 to 0.63256, saving model to ./model\\018-0.6326.h5\n",
      "21/21 [==============================] - 111s 5s/step - loss: 0.6860 - accuracy: 0.7385 - val_loss: 0.6326 - val_accuracy: 0.7688\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.7042 - accuracy: 0.7492\n",
      "Epoch 19: val_loss did not improve from 0.63256\n",
      "21/21 [==============================] - 105s 5s/step - loss: 0.7042 - accuracy: 0.7492 - val_loss: 0.6740 - val_accuracy: 0.7500\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.6553 - accuracy: 0.7554\n",
      "Epoch 20: val_loss did not improve from 0.63256\n",
      "21/21 [==============================] - 106s 5s/step - loss: 0.6553 - accuracy: 0.7554 - val_loss: 0.6787 - val_accuracy: 0.7437\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.6229 - accuracy: 0.7615\n",
      "Epoch 21: val_loss did not improve from 0.63256\n",
      "21/21 [==============================] - 107s 5s/step - loss: 0.6229 - accuracy: 0.7615 - val_loss: 0.6392 - val_accuracy: 0.7312\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.6246 - accuracy: 0.7859\n",
      "Epoch 22: val_loss improved from 0.63256 to 0.59403, saving model to ./model\\022-0.5940.h5\n",
      "21/21 [==============================] - 112s 5s/step - loss: 0.6246 - accuracy: 0.7859 - val_loss: 0.5940 - val_accuracy: 0.8188\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.6617 - accuracy: 0.7634\n",
      "Epoch 23: val_loss did not improve from 0.59403\n",
      "21/21 [==============================] - 108s 5s/step - loss: 0.6617 - accuracy: 0.7634 - val_loss: 0.6995 - val_accuracy: 0.7625\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.6203 - accuracy: 0.7661\n",
      "Epoch 24: val_loss improved from 0.59403 to 0.56509, saving model to ./model\\024-0.5651.h5\n",
      "21/21 [==============================] - 110s 5s/step - loss: 0.6203 - accuracy: 0.7661 - val_loss: 0.5651 - val_accuracy: 0.8188\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.4720 - accuracy: 0.8196\n",
      "Epoch 25: val_loss did not improve from 0.56509\n",
      "21/21 [==============================] - 107s 5s/step - loss: 0.4720 - accuracy: 0.8196 - val_loss: 0.5829 - val_accuracy: 0.7812\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.4902 - accuracy: 0.8043\n",
      "Epoch 26: val_loss did not improve from 0.56509\n",
      "21/21 [==============================] - 110s 5s/step - loss: 0.4902 - accuracy: 0.8043 - val_loss: 0.5885 - val_accuracy: 0.8125\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.8104\n",
      "Epoch 27: val_loss did not improve from 0.56509\n",
      "21/21 [==============================] - 99s 5s/step - loss: 0.5080 - accuracy: 0.8104 - val_loss: 0.6050 - val_accuracy: 0.8188\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.4256 - accuracy: 0.8502\n",
      "Epoch 28: val_loss improved from 0.56509 to 0.49283, saving model to ./model\\028-0.4928.h5\n",
      "21/21 [==============================] - 101s 5s/step - loss: 0.4256 - accuracy: 0.8502 - val_loss: 0.4928 - val_accuracy: 0.8062\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.4099 - accuracy: 0.8593\n",
      "Epoch 29: val_loss did not improve from 0.49283\n",
      "21/21 [==============================] - 97s 5s/step - loss: 0.4099 - accuracy: 0.8593 - val_loss: 0.5456 - val_accuracy: 0.7688\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.8272\n",
      "Epoch 30: val_loss did not improve from 0.49283\n",
      "21/21 [==============================] - 100s 5s/step - loss: 0.4748 - accuracy: 0.8272 - val_loss: 0.5803 - val_accuracy: 0.8062\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.8685\n",
      "Epoch 31: val_loss improved from 0.49283 to 0.48791, saving model to ./model\\031-0.4879.h5\n",
      "21/21 [==============================] - 108s 5s/step - loss: 0.3505 - accuracy: 0.8685 - val_loss: 0.4879 - val_accuracy: 0.8313\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3561 - accuracy: 0.8792\n",
      "Epoch 32: val_loss improved from 0.48791 to 0.45454, saving model to ./model\\032-0.4545.h5\n",
      "21/21 [==============================] - 107s 5s/step - loss: 0.3561 - accuracy: 0.8792 - val_loss: 0.4545 - val_accuracy: 0.8500\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3372 - accuracy: 0.8716\n",
      "Epoch 33: val_loss did not improve from 0.45454\n",
      "21/21 [==============================] - 95s 5s/step - loss: 0.3372 - accuracy: 0.8716 - val_loss: 0.5492 - val_accuracy: 0.8313\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3791 - accuracy: 0.8761\n",
      "Epoch 34: val_loss did not improve from 0.45454\n",
      "21/21 [==============================] - 97s 5s/step - loss: 0.3791 - accuracy: 0.8761 - val_loss: 0.5840 - val_accuracy: 0.8250\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3604 - accuracy: 0.8670\n",
      "Epoch 35: val_loss did not improve from 0.45454\n",
      "21/21 [==============================] - 95s 5s/step - loss: 0.3604 - accuracy: 0.8670 - val_loss: 0.4856 - val_accuracy: 0.8250\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3015 - accuracy: 0.8930\n",
      "Epoch 36: val_loss did not improve from 0.45454\n",
      "21/21 [==============================] - 93s 4s/step - loss: 0.3015 - accuracy: 0.8930 - val_loss: 0.4769 - val_accuracy: 0.8687\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3505 - accuracy: 0.8930\n",
      "Epoch 37: val_loss did not improve from 0.45454\n",
      "21/21 [==============================] - 98s 5s/step - loss: 0.3505 - accuracy: 0.8930 - val_loss: 0.5033 - val_accuracy: 0.8313\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3371 - accuracy: 0.8823\n",
      "Epoch 38: val_loss did not improve from 0.45454\n",
      "21/21 [==============================] - 103s 5s/step - loss: 0.3371 - accuracy: 0.8823 - val_loss: 0.4950 - val_accuracy: 0.8375\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2894 - accuracy: 0.8899\n",
      "Epoch 39: val_loss improved from 0.45454 to 0.43891, saving model to ./model\\039-0.4389.h5\n",
      "21/21 [==============================] - 111s 5s/step - loss: 0.2894 - accuracy: 0.8899 - val_loss: 0.4389 - val_accuracy: 0.8438\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3065 - accuracy: 0.8976\n",
      "Epoch 40: val_loss did not improve from 0.43891\n",
      "21/21 [==============================] - 98s 5s/step - loss: 0.3065 - accuracy: 0.8976 - val_loss: 0.4770 - val_accuracy: 0.8562\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2749 - accuracy: 0.9159\n",
      "Epoch 41: val_loss did not improve from 0.43891\n",
      "21/21 [==============================] - 99s 5s/step - loss: 0.2749 - accuracy: 0.9159 - val_loss: 0.4715 - val_accuracy: 0.8625\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2883 - accuracy: 0.9098\n",
      "Epoch 42: val_loss did not improve from 0.43891\n",
      "21/21 [==============================] - 100s 5s/step - loss: 0.2883 - accuracy: 0.9098 - val_loss: 0.4467 - val_accuracy: 0.8438\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2808 - accuracy: 0.9144\n",
      "Epoch 43: val_loss did not improve from 0.43891\n",
      "21/21 [==============================] - 95s 5s/step - loss: 0.2808 - accuracy: 0.9144 - val_loss: 0.4556 - val_accuracy: 0.8188\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2578 - accuracy: 0.9083\n",
      "Epoch 44: val_loss did not improve from 0.43891\n",
      "21/21 [==============================] - 91s 4s/step - loss: 0.2578 - accuracy: 0.9083 - val_loss: 0.5132 - val_accuracy: 0.8062\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.9226\n",
      "Epoch 45: val_loss improved from 0.43891 to 0.41056, saving model to ./model\\045-0.4106.h5\n",
      "21/21 [==============================] - 105s 5s/step - loss: 0.2132 - accuracy: 0.9226 - val_loss: 0.4106 - val_accuracy: 0.8750\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2530 - accuracy: 0.9159\n",
      "Epoch 46: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 94s 5s/step - loss: 0.2530 - accuracy: 0.9159 - val_loss: 0.5560 - val_accuracy: 0.8625\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3003 - accuracy: 0.8945\n",
      "Epoch 47: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 107s 5s/step - loss: 0.3003 - accuracy: 0.8945 - val_loss: 0.5612 - val_accuracy: 0.8625\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2182 - accuracy: 0.9281\n",
      "Epoch 48: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 106s 5s/step - loss: 0.2182 - accuracy: 0.9281 - val_loss: 0.5132 - val_accuracy: 0.8500\n",
      "Epoch 49/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2447 - accuracy: 0.9220\n",
      "Epoch 49: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 98s 5s/step - loss: 0.2447 - accuracy: 0.9220 - val_loss: 0.5502 - val_accuracy: 0.8375\n",
      "Epoch 50/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3367 - accuracy: 0.8976\n",
      "Epoch 50: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 97s 5s/step - loss: 0.3367 - accuracy: 0.8976 - val_loss: 0.5147 - val_accuracy: 0.8375\n",
      "Epoch 51/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.3219 - accuracy: 0.9006\n",
      "Epoch 51: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 103s 5s/step - loss: 0.3219 - accuracy: 0.9006 - val_loss: 0.5696 - val_accuracy: 0.8500\n",
      "Epoch 52/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2815 - accuracy: 0.8945\n",
      "Epoch 52: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 107s 5s/step - loss: 0.2815 - accuracy: 0.8945 - val_loss: 0.4258 - val_accuracy: 0.8750\n",
      "Epoch 53/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2076 - accuracy: 0.9159\n",
      "Epoch 53: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 109s 5s/step - loss: 0.2076 - accuracy: 0.9159 - val_loss: 0.5559 - val_accuracy: 0.8875\n",
      "Epoch 54/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.9083\n",
      "Epoch 54: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 101s 5s/step - loss: 0.2912 - accuracy: 0.9083 - val_loss: 0.5559 - val_accuracy: 0.8750\n",
      "Epoch 55/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2641 - accuracy: 0.9235\n",
      "Epoch 55: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 101s 5s/step - loss: 0.2641 - accuracy: 0.9235 - val_loss: 0.4961 - val_accuracy: 0.8500\n",
      "Epoch 56/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1620 - accuracy: 0.9343\n",
      "Epoch 56: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 100s 5s/step - loss: 0.1620 - accuracy: 0.9343 - val_loss: 0.5779 - val_accuracy: 0.8375\n",
      "Epoch 57/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2431 - accuracy: 0.9266\n",
      "Epoch 57: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 99s 5s/step - loss: 0.2431 - accuracy: 0.9266 - val_loss: 0.4544 - val_accuracy: 0.8750\n",
      "Epoch 58/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1879 - accuracy: 0.9388\n",
      "Epoch 58: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 100s 5s/step - loss: 0.1879 - accuracy: 0.9388 - val_loss: 0.5038 - val_accuracy: 0.8750\n",
      "Epoch 59/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.9327\n",
      "Epoch 59: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 99s 5s/step - loss: 0.2057 - accuracy: 0.9327 - val_loss: 0.5409 - val_accuracy: 0.8562\n",
      "Epoch 60/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1877 - accuracy: 0.9312\n",
      "Epoch 60: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 99s 5s/step - loss: 0.1877 - accuracy: 0.9312 - val_loss: 0.5114 - val_accuracy: 0.8687\n",
      "Epoch 61/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1719 - accuracy: 0.9358\n",
      "Epoch 61: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 100s 5s/step - loss: 0.1719 - accuracy: 0.9358 - val_loss: 0.4858 - val_accuracy: 0.8625\n",
      "Epoch 62/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1437 - accuracy: 0.9511\n",
      "Epoch 62: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 100s 5s/step - loss: 0.1437 - accuracy: 0.9511 - val_loss: 0.5775 - val_accuracy: 0.8562\n",
      "Epoch 63/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 0.9327\n",
      "Epoch 63: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 102s 5s/step - loss: 0.1767 - accuracy: 0.9327 - val_loss: 0.4514 - val_accuracy: 0.8750\n",
      "Epoch 64/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1551 - accuracy: 0.9388\n",
      "Epoch 64: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 103s 5s/step - loss: 0.1551 - accuracy: 0.9388 - val_loss: 0.5370 - val_accuracy: 0.8562\n",
      "Epoch 65/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2349 - accuracy: 0.9144\n",
      "Epoch 65: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 100s 5s/step - loss: 0.2349 - accuracy: 0.9144 - val_loss: 0.5637 - val_accuracy: 0.8625\n",
      "Epoch 66/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1444 - accuracy: 0.9419\n",
      "Epoch 66: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 100s 5s/step - loss: 0.1444 - accuracy: 0.9419 - val_loss: 0.6124 - val_accuracy: 0.8250\n",
      "Epoch 67/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1892 - accuracy: 0.9330\n",
      "Epoch 67: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 105s 5s/step - loss: 0.1892 - accuracy: 0.9330 - val_loss: 0.4696 - val_accuracy: 0.8750\n",
      "Epoch 68/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.9495\n",
      "Epoch 68: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 104s 5s/step - loss: 0.1509 - accuracy: 0.9495 - val_loss: 0.4489 - val_accuracy: 0.8938\n",
      "Epoch 69/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1341 - accuracy: 0.9526\n",
      "Epoch 69: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 103s 5s/step - loss: 0.1341 - accuracy: 0.9526 - val_loss: 0.5767 - val_accuracy: 0.8625\n",
      "Epoch 70/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1593 - accuracy: 0.9358\n",
      "Epoch 70: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 102s 5s/step - loss: 0.1593 - accuracy: 0.9358 - val_loss: 0.7044 - val_accuracy: 0.8375\n",
      "Epoch 71/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1862 - accuracy: 0.9404\n",
      "Epoch 71: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 107s 5s/step - loss: 0.1862 - accuracy: 0.9404 - val_loss: 0.5177 - val_accuracy: 0.8750\n",
      "Epoch 72/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1381 - accuracy: 0.9511\n",
      "Epoch 72: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 105s 5s/step - loss: 0.1381 - accuracy: 0.9511 - val_loss: 0.6669 - val_accuracy: 0.8438\n",
      "Epoch 73/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.9648\n",
      "Epoch 73: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 104s 5s/step - loss: 0.1485 - accuracy: 0.9648 - val_loss: 0.6239 - val_accuracy: 0.8562\n",
      "Epoch 74/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.9541\n",
      "Epoch 74: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 103s 5s/step - loss: 0.1627 - accuracy: 0.9541 - val_loss: 0.6139 - val_accuracy: 0.8687\n",
      "Epoch 75/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2116 - accuracy: 0.9388\n",
      "Epoch 75: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 104s 5s/step - loss: 0.2116 - accuracy: 0.9388 - val_loss: 0.5563 - val_accuracy: 0.8438\n",
      "Epoch 76/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1808 - accuracy: 0.9419\n",
      "Epoch 76: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 106s 5s/step - loss: 0.1808 - accuracy: 0.9419 - val_loss: 0.5156 - val_accuracy: 0.8750\n",
      "Epoch 77/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2027 - accuracy: 0.9327\n",
      "Epoch 77: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 104s 5s/step - loss: 0.2027 - accuracy: 0.9327 - val_loss: 0.4479 - val_accuracy: 0.8938\n",
      "Epoch 78/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 0.9541\n",
      "Epoch 78: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 103s 5s/step - loss: 0.1399 - accuracy: 0.9541 - val_loss: 0.5107 - val_accuracy: 0.8687\n",
      "Epoch 79/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.1615 - accuracy: 0.9388\n",
      "Epoch 79: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 105s 5s/step - loss: 0.1615 - accuracy: 0.9388 - val_loss: 0.5443 - val_accuracy: 0.8625\n",
      "Epoch 80/1000\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.2115 - accuracy: 0.9327\n",
      "Epoch 80: val_loss did not improve from 0.41056\n",
      "21/21 [==============================] - 117s 6s/step - loss: 0.2115 - accuracy: 0.9327 - val_loss: 0.4890 - val_accuracy: 0.8875\n",
      "Epoch 81/1000\n",
      " 1/21 [>.............................] - ETA: 1:37 - loss: 0.1024 - accuracy: 0.9688"
     ]
    }
   ],
   "source": [
    "train_step = num_train//BATCH_SIZE\n",
    "val_step = num_val//BATCH_SIZE\n",
    "\n",
    "filepath = \"./model/{epoch:03d}-{val_loss:.4f}.h5\"\n",
    "check_point = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    save_best_only = True,\n",
    "    verbose = True\n",
    ")\n",
    "early_stop_point = keras.callbacks.EarlyStopping(patience=100)\n",
    "\n",
    "hist = finetune_model.fit(\n",
    "    train_ds, epochs=1000,\n",
    "    steps_per_epoch=train_step,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=val_step,\n",
    "    callbacks = [check_point, early_stop_point]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d9dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history[\"loss\"], c='b', label=\"train_loss\")\n",
    "plt.plot(hist.history[\"val_loss\"], c='r', label=\"val loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7b6829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
