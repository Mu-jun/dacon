{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4642be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b830a8",
   "metadata": {},
   "source": [
    "# 디렉터리로 클래스 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5595a940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>file_name</th>\n",
       "      <th>class</th>\n",
       "      <th>state</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10000.png</td>\n",
       "      <td>transistor</td>\n",
       "      <td>good</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10001.png</td>\n",
       "      <td>capsule</td>\n",
       "      <td>good</td>\n",
       "      <td>capsule-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10002.png</td>\n",
       "      <td>transistor</td>\n",
       "      <td>good</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10003.png</td>\n",
       "      <td>wood</td>\n",
       "      <td>good</td>\n",
       "      <td>wood-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10004.png</td>\n",
       "      <td>bottle</td>\n",
       "      <td>good</td>\n",
       "      <td>bottle-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  file_name       class state            label\n",
       "0      0  10000.png  transistor  good  transistor-good\n",
       "1      1  10001.png     capsule  good     capsule-good\n",
       "2      2  10002.png  transistor  good  transistor-good\n",
       "3      3  10003.png        wood  good        wood-good\n",
       "4      4  10004.png      bottle  good      bottle-good"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./dataset/train_df.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "302f882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df[\"file_name\"].to_numpy()\n",
    "target = train_df[\"label\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aaac0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"./dataset/main_directory/\"\n",
    "test_path = \"./dataset/test/\"\n",
    "\n",
    "if not os.path.exists(train_path):\n",
    "        os.mkdir(train_path)\n",
    "\n",
    "for label in train_df[\"label\"].unique():\n",
    "    if not os.path.exists(train_path+label):\n",
    "        os.mkdir(train_path+label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00701c5",
   "metadata": {},
   "source": [
    "for file, label in zip(train,target):\n",
    "    src = \"./dataset/train/\"+file\n",
    "    new_filename = label + '_train_' + file\n",
    "    dst = os.path.join(train_path,label,new_filename)\n",
    "    shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af512893",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2019b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (224,224,3)\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0779fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(filename):\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img,INPUT_SHAPE[:2])\n",
    "    return img\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de6fc6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottle-broken_large\n"
     ]
    }
   ],
   "source": [
    "classes = os.listdir(train_path)\n",
    "num_classes = len(classes)\n",
    "filenames = glob(train_path+'*/*')\n",
    "num_images = len(filenames)\n",
    "print(filenames[0].split(os.sep)[-2])\n",
    "random.shuffle(filenames)\n",
    "labels = [classes.index(name.split(os.sep)[-2]) for name in filenames]\n",
    "\n",
    "filenames_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "images_ds = filenames_ds.map(\n",
    "    parse_image,\n",
    "    num_parallel_calls=AUTOTUNE\n",
    ")\n",
    "labels_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "\n",
    "ds = tf.data.Dataset.zip((images_ds, labels_ds))\n",
    "ds = configure_for_performance(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b12369",
   "metadata": {},
   "source": [
    "# 데이터 전처리 층만들기\n",
    "## evaluate() 또는 predict() 호출 시에는 자동으로 비활성화 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ee8c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    keras.layers.experimental.preprocessing.RandomTranslation(0.1,0.1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "103a8d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_model = keras.applications.VGG16(\n",
    "    input_shape= INPUT_SHAPE,\n",
    "    include_top= False,\n",
    "    weights= 'imagenet',\n",
    ")\n",
    "transfer_model.trainable = False\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ac2f51f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_1 (Sequential)   (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " rescaling_2 (Rescaling)     (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 88)                2207832   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,922,520\n",
      "Trainable params: 2,207,832\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "finetune_model = keras.Sequential([\n",
    "    keras.Input(shape=INPUT_SHAPE),\n",
    "    data_augmentation,\n",
    "    keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    transfer_model,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "],\"VGG16\")\n",
    "finetune_model.summary()\n",
    "\n",
    "finetune_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer=keras.optimizers.Adam(learning_rate=0.0002),\n",
    "                       metrics='accuracy')                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a25ae08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "133/133 [==============================] - 719s 5s/step - loss: 1.0414 - accuracy: 0.8419\n",
      "Epoch 2/2\n",
      "133/133 [==============================] - 729s 5s/step - loss: 0.7700 - accuracy: 0.8424\n"
     ]
    }
   ],
   "source": [
    "step = num_images//BATCH_SIZE\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "hist = finetune_model.fit(\n",
    "    ds, epochs=2, steps_per_epoch=step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d5fbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in ds.take(2):\n",
    "    print(j.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
